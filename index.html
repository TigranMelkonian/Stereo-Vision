html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title> CS585 Project: Stereo Matching  </title>
<style>
<!--
body{
font-family: 'Trebuchet MS', Verdana;
}
p{
font-family: 'Trebuchet MS', Times;
margin: 10px 10px 15px 20px;
text-indent:50px;
}
h3{
margin: 5px;
}
h2{
margin: 10px;
}
h1{
margin: 10px 0px 0px 20px;
}
div.main-body{
align:center;
margin: 30px;
}
hr{
margin:20px 0px 20px 0px;
}
-->
</style>
<style type="text/css">span[data-cmchighlight=''] {padding:0px!important;margin:0px!important;display:inline!important;float:none!important;position:static!important;-webkit-print-color-adjust:exact!important}</style><style type="text/css">.cmcredaction {color:#D3D3D3!important;background:#D3D3D3!important;-webkit-user-select:none!important;-khtml-user-select:none !important;-moz-user-select:none!important;-ms-user-select:none!important;-o-user-select:none!important;user-select:none!important;-webkit-print-color-adjust:exact!important}</style></head>

<body style="zoom: 1;">
<center>
<a href="http://www.bu.edu/"><img border="0" src="./cs585_ivc_project_materials/bu-logo.gif" width="119" height="120"></a>
</center>

<h1>CS585 IVC Project: Stereo Matching</h1>
<h4>
	<p>
	CS 585 IVC Project
	</p>
</h4>

<h4>
	<p>
	Tigran Melkonian, Mingrui Yang, Wei Jiang
</p>
</h4>

<h4>
	<p>
	2017-12-07
</p>
</h4>

<div class="main-body">
<hr>
<h2> Problem Definition </h2>
<p>
  Stereo matching, the extraction of depth information from digital images, is one of the most heavily investigated topics in computer vision with many applications in entertainment, object recognition,information transfer, and automated systems. In this project, we want to implement a stereo matching algorithm. The baseline approach is through the traditional block matching algorithm. Our goal is to explore an improved method for detecting objects in stereo images and calculating a more accurate correspondence between two images. We plan on initially utilizing the middlebury dataset, of two-frame stereo images, because it provides us high quality ground truth images and calibration data. Additionally, we plan on exploring filtering methods for both de-noising and hole-filling in depth maps. To challenge ourselves, we want to extend the algorithm to non-parallel camera settings for example the bats over the lake.  
</p>

    

<hr>
<h2> Dataset and Desired Results</h2>
<h4>
	<p>
	We get our datasets from the website: 
	<a href="http://vision.middlebury.edu/stereo/">
	http://vision.middlebury.edu/stereo/
	</a>
	</p>
</h4>

<p>
<h3> 1. Middlebury dataset </h3>
</p>
<p>
    Left view: </br>
<img src="./cs585_ivc_project_materials/dataset/left_view.png", style="width:30%; height:auto"> </br>
</p>
<p>
    Right view: </br>
<img src="./cs585_ivc_project_materials/dataset/right_view.png", style="width:30%; height:auto"> </br>
</p>
<p>
<h3> 2. Desired results </h3>
</p>
<p>
    Left view ground truth: </br>
<img src="./cs585_ivc_project_materials/dataset/left_depth.png", style="width:30%; height:auto"> </br>
</p>
<p>
    Right view ground truth: </br>
<img src="./cs585_ivc_project_materials/dataset/right_depth.png", style="width:30%; height:auto"> </br>
</p>



    
<hr>
<h2> Background Research and Methods</h2>
<p>
</p>
<h3> 
	<p><i><u>
	Step 1. Introduction 
	</u></i></p>
</h3>
<p>
	In this problem, we focused on the problem of a simple binocular camera setting, which means the left and right camera has the same lens, film, and resolution. In addition, the two cameras only shift in horizontal direction, which means the image pairs are already rectified.  </br>

For a point in the scene, if we know the location of that point in the left image and right image, we can calculate the offset of the two pixels. Together with the baseline, length of focus, the width of pixels on the film, we can calculate the depth value of that pixel using the equation: Z = (b*f)/disparity; 
</p>

<h3> 
	<p><i><u>
	Step 2. Basic block matching 
	</u></i></p>
</h3>
<p>
	In the second part, we need to perform basic block matching. At this part, we should to find the most possible corresponding pixels between two parallel images. Here we define the corresponding block size to 7-by-7 pixel block. So, for every pixel in the right image, we extract 7-by-7 pixel block and search for the block that best matches it. Since two images are rectified and on the same row, so we just need to search along the same row for every pixel. We restrict the search area to 50 pixels to make the algorithm simpler and more accurate. In our algorithm, we use the sum of absolute differences (SAD) to compare the image regions. </br>

</p>

Disparity map from basic block matching:</br>
Using search range 50 and block size 7.</br>
The total run time is 72.3s.</br>
<img src="./cs585_ivc_project_materials/results/basic_block_matching.png", style="width:30%; height:auto"> </br>

<p>
	However, in the result we find many noisy patches and bad depth estimates, especially on the ceiling. We find that this problem is caused by the similarities between pixels. That means there are no strong image features and differences between two 7-by-7 blocks so that our matching process regards them as the best match blocks. </br>
</p>

<p>
So, we have to solve this problem and improve the result in the later steps.</br>

</p>
<p>
	For display purposes, we saturate the depth map to have only positive values. In general, slight angular misalignment of the stereo cameras used for image acquisition can allow both positive and negative disparities to appear validly in the depth map. In this case, however, the stereo cameras were near perfectly parallel, so the true disparities have only one sign. Thus this correction is valid.
</p>

<h3> 
	<p><i><u>
	Step 3. Subpixel estimation 
	</u></i></p>
</h3>
<p>
	The above depth map depicts results where there are no smooth transitions between regions of varying disparity. We can solve this by incorporating subpixel estimation into the matching criteria. We now consider the minimum cost and the two neighboring costs. Finally, we systematically calculate the minimum to get the sub pixel correction values. 
</p>
<p>
Disparity map with subpixel estimation:</br>
<img src="./cs585_ivc_project_materials/results/stereo_matching_subpixel.png", style="width:30%; height:auto"> </br>
</p>

<h3> 
	<p><i><u>
	Step 4. Dynamic programming 
	</u></i></p>
</h3>
<p>
As you can see from the above results: the disparity map is not very smooth, which means some black holes or white holes will appear in the disparity maps generated by basic block matching.</br>

We believe the reasons behind this un-smoothness is that some areas don’t have enough details or textures for the block matching algorithm to find the correct correspondences.</br>

To solve this problem, researchers introduced a method to find the path for each row with the smallest sum of costs. The cost is also calculated by SAD. But this time, we do not find the location with the lowest SAD for a single pixel. We add the penalty values for the discontinuities of two adjacent pixels. </br>

To find the path with lowest cost, we utilized dynamic programming.First, we construct a cost matrix, for every pixels in a row. Then from the bottom of the matrix, we will find the lowest cost connection to next pixel and add the cost to next level. We repeat the process till the first row of the matrix. Then we will choose the pixel with the lowest sum of cost and find the path lead to that pixel. </br>

Additionally, we developed an adaptive window method to  evaluate the cost based on the density of Canny edges. We believe the Canny edge represents the density of textures or details, so for the areas where the details are sparse, we need a larger window to find the correspondence. </br>

During the development of the algorithm, we found several tricks for the correspondence problem. 1: Use the RGB channels will give use better cost evaluation than using only brightness. 2. Adaptive windows can resolve some artifact where the textures or details are sparse. </br>

</p>
<p>
Used the brightness value to calculate the cost:</br>
The total run time is 163.4s.</br>
<img src="./cs585_ivc_project_materials/results/dp_brightness_disparity.png", style="width:30%; height:auto"> </br>
</p>
<p>
Used the RGB value to calculate the cost:</br>
<img src="./cs585_ivc_project_materials/results/dp_rgb_disparity.png", style="width:30%; height:auto"> </br>
</p>
<p>
Used the RGB value to calculate the cost:</br>
Used adaptive window based on the density of Canny edges</br>
<img src="./cs585_ivc_project_materials/results/disparity_adaptive.png", style="width:30%; height:auto"> </br>
</p>
<h3> 
	<p><i><u>
	Step 5. Image Pyramiding 
	</u></i></p>
</h3>
<p>
	We can use image pyramiding and telescopic search in order to reduce the high operation costs that we encountered with basic block matching and dynamic programing. Using a full-sized image, we searched over a ±15-­pixel range to detect the disparities in the image. However, if we had down­sized the image by a factor of two, this search range could have been reduced to ±7 pixels on an image a quarter of the area, meaning this step would reduce the cost by a factor of 8. Finally, we used the disparity estimates from this operation to initialize the search on the larger image, and therefore only needed to search a smaller range of disparities.
    
</p>
<p>
Used full size and half size images to construct a 2 levels pyramid:</br>
For the half size image used search range as 25 with basic block matching.</br>
The total run time is 26.4s.</br>
<img src="./cs585_ivc_project_materials/results/pyramid_block_matching.png", style="width:30%; height:auto"> </br>
</p>
<p>
Illustration:</br>
<img src="./cs585_ivc_project_materials/results/pyramid_block_matching_2.png", style="width:30%; height:auto"> </br>
</p>

<hr>
<h2> Credits and Bibliography </h2>
<p>
Reference: <br />
1. Veksler, Olga. "Stereo correspondence by dynamic programming on a tree." Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on. Vol. 2. IEEE, 2005. </br>
2. Ohta, Yuichi, and Takeo Kanade. "Stereo by intra-and inter-scanline search using dynamic programming." IEEE Transactions on pattern analysis and machine intelligence 2 (1985): 139-154. </br>
3. Park, Chang Seob, and Hyun Wook Park. "A robust stereo disparity estimation using adaptive window search and dynamic programming search." Pattern Recognition 34.12 (2001): 2573-2576. </br>
4. Opencv function documentation, http://docs.opencv.org/ </br>
5. Scharstein, Daniel, and Richard Szeliski. "High-accuracy stereo depth maps using structured light." Computer Vision and Pattern Recognition, 2003. Proceedings. 2003 IEEE Computer Society Conference on. Vol. 1. IEEE, 2003. </br>
</p>
<p>
Teammates: <br />
Tigran Melkonian, Mingrui Yang, Wei Jiang.<br />
</p>
<hr>
</div>


</body></html>

